{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch_5_p326_scaling_normalization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPuxQEiXRbfStPgKZFO5jhd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kohyouseob/Python_ML/blob/main/Ch_5_p326_scaling_normalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb_-P6gFsmye"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt \r\n",
        "import pandas as pd \r\n",
        "import seaborn as sns\r\n",
        "from scipy import stats\r\n",
        "from sklearn.datasets import load_boston\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "# boston 데이터 세트 로드\r\n",
        "boston = load_boston()\r\n",
        "\r\n",
        "# boston 데이터 세트 DataFrame변환\r\n",
        "boston_df = pd.DataFrame(boston.data, columns=boston.feature_names)\r\n",
        "\r\n",
        "# boston 데이터 세트의 target 배열은 주택 가격임, 이를 PRICE 칼럼으로 DataFrame에 추가함\r\n",
        "boston_df['PRICE'] = boston.target"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTw5DKNzs16Q"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "from sklearn.metrics import mean_squared_error, r2_score\r\n",
        "\r\n",
        "y_target = boston_df['PRICE']\r\n",
        "X_data = boston_df.drop(['PRICE'], axis=1, inplace=False)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdxngDfWtpbJ"
      },
      "source": [
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "\r\n",
        "# alpha 값에 따른 회귀 모델의 폴드 평균 RMSE를 출력하고 회귀 계수값들을 DataFrame으로 반환\r\n",
        "def get_linear_reg_eval(model_name, params=None, X_data_n=None, y_target_n=None, verbose=True):\r\n",
        "    coeff_df = pd.DataFrame()\r\n",
        "    if verbose : print('####### ', model_name, ' ######')\r\n",
        "    for param in params:\r\n",
        "        if model_name == 'Ridge' : model = Ridge(alpha=param)\r\n",
        "        elif model_name == 'Lasso' : model = Lasso(alpha=param)\r\n",
        "        elif model_name == 'ElasticNet' : model = ElasticNet(alpha=param, l1_ratio=0.7)\r\n",
        "        neg_mse_scores = cross_val_score(model, X_data_n, y_target_n, scoring=\"neg_mean_squared_error\", cv=5)\r\n",
        "        avg_rmse = np.mean(np.sqrt(-1 * neg_mse_scores))\r\n",
        "        print('alpha {0}일 때 5 폴드 세트의 평균 RMSE : {1:.3f}'.format(param, avg_rmse))\r\n",
        "        # cross_val_score는 evaluation metric만 반환하므로 모델을 다시 학습하여 회귀 계수 추출\r\n",
        "        model.fit(X_data, y_target)\r\n",
        "        # alpha에 따른 피처별 회귀 계수를 Series로 변환하고 이를 DataFrame의 칼럼으로 추가\r\n",
        "        coeff = pd.Series(data=model.coef_, index=X_data.columns)\r\n",
        "        colname='alpha:'+str(param)\r\n",
        "        coeff_df[colname] = coeff \r\n",
        "    return coeff_df\r\n",
        "# end of get_linear_regre_eval"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL3DzXIqs4LY"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\r\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\r\n",
        "\r\n",
        "# Method는 표준 정규 분포 변환(Standard), 최대값/최소값 정규화(MinMax), 로그변환(Log) 결정\r\n",
        "# p_degree는 다항식 특성을 추가할 때 적용. p_degree는 2이상 부여하지 않음\r\n",
        "def get_scaled_data(method='None', p_degree=None, input_data=None):\r\n",
        "    if method == 'Standard': \r\n",
        "       scaled_data = StandardScaler().fit_transform(input_data) # 표준 정규분포\r\n",
        "    elif method == 'MinMax': \r\n",
        "       scaled_data = MinMaxScaler().fit_transform(input_data)   # 최대값/최소값 정규화\r\n",
        "    elif method == 'Log':    \r\n",
        "       scaled_data = np.log1p(input_data)                       # 로그변환(Log)\r\n",
        "    else:\r\n",
        "       scaled_data = input_data\r\n",
        "    \r\n",
        "    if p_degree != None:\r\n",
        "       scaled_data = PolynomialFeatures(degree=p_degree, include_bias=False).fit_transform(scaled_data)\r\n",
        "\r\n",
        "    return scaled_data"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q0D0Jhbul_X",
        "outputId": "d4786eab-4800-4635-9468-262b8839dc33"
      },
      "source": [
        "# Ridge의 alpha값을 다르게 적용하고 다양한 데이터 변환 방법에 따른 RMSE 추출\r\n",
        "alphas = [0.1, 1, 10, 100]\r\n",
        "\r\n",
        "# 5개 방식으로 변환, 먼저 원본 그대로, 표준정규 분포, 표준정규 분포+다항식 특성\r\n",
        "# 최대/최소 정규화, 최대/최소 정규화+다항식 특성, 로그변환\r\n",
        "scale_methods = [(None, None), ('Standard', None), ('Standard', 2),\r\n",
        "                 ('MinMax', None), ('MinMax', 2), ('Log', None)]\r\n",
        "\r\n",
        "for scale_method in scale_methods:\r\n",
        "    X_data_scaled = get_scaled_data(method=scale_method[0], p_degree=scale_method[1], input_data=X_data)\r\n",
        "    print('\\n## 변환 유형:{0}, Polynomial Degree: {1}'.format(scale_method[0], scale_method[1]))\r\n",
        "    get_linear_reg_eval('Ridge', params=alphas, X_data_n=X_data_scaled, y_target_n=y_target, verbose=False)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "## 변환 유형:None, Polynomial Degree: None\n",
            "alpha 0.1일 때 5 폴드 세트의 평균 RMSE : 5.788\n",
            "alpha 1일 때 5 폴드 세트의 평균 RMSE : 5.653\n",
            "alpha 10일 때 5 폴드 세트의 평균 RMSE : 5.518\n",
            "alpha 100일 때 5 폴드 세트의 평균 RMSE : 5.330\n",
            "\n",
            "## 변환 유형:Standard, Polynomial Degree: None\n",
            "alpha 0.1일 때 5 폴드 세트의 평균 RMSE : 5.826\n",
            "alpha 1일 때 5 폴드 세트의 평균 RMSE : 5.803\n",
            "alpha 10일 때 5 폴드 세트의 평균 RMSE : 5.637\n",
            "alpha 100일 때 5 폴드 세트의 평균 RMSE : 5.421\n",
            "\n",
            "## 변환 유형:Standard, Polynomial Degree: 2\n",
            "alpha 0.1일 때 5 폴드 세트의 평균 RMSE : 8.827\n",
            "alpha 1일 때 5 폴드 세트의 평균 RMSE : 6.871\n",
            "alpha 10일 때 5 폴드 세트의 평균 RMSE : 5.485\n",
            "alpha 100일 때 5 폴드 세트의 평균 RMSE : 4.634\n",
            "\n",
            "## 변환 유형:MinMax, Polynomial Degree: None\n",
            "alpha 0.1일 때 5 폴드 세트의 평균 RMSE : 5.764\n",
            "alpha 1일 때 5 폴드 세트의 평균 RMSE : 5.465\n",
            "alpha 10일 때 5 폴드 세트의 평균 RMSE : 5.754\n",
            "alpha 100일 때 5 폴드 세트의 평균 RMSE : 7.635\n",
            "\n",
            "## 변환 유형:MinMax, Polynomial Degree: 2\n",
            "alpha 0.1일 때 5 폴드 세트의 평균 RMSE : 5.298\n",
            "alpha 1일 때 5 폴드 세트의 평균 RMSE : 4.323\n",
            "alpha 10일 때 5 폴드 세트의 평균 RMSE : 5.185\n",
            "alpha 100일 때 5 폴드 세트의 평균 RMSE : 6.538\n",
            "\n",
            "## 변환 유형:Log, Polynomial Degree: None\n",
            "alpha 0.1일 때 5 폴드 세트의 평균 RMSE : 4.770\n",
            "alpha 1일 때 5 폴드 세트의 평균 RMSE : 4.676\n",
            "alpha 10일 때 5 폴드 세트의 평균 RMSE : 4.836\n",
            "alpha 100일 때 5 폴드 세트의 평균 RMSE : 6.241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNiGPouRwQPG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}